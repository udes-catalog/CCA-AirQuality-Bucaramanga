# ğŸ› ï¸ Instructions for Using the RYFoR Dataset Template

This guide walks you through the steps required to use, adapt, and share your own dataset based on this template. The goal is to help you stay aligned with FAIR principles and good research data practices.

## ğŸ“š Table of Contents

0. [ğŸš€ Getting Started](#-getting-started)
1. [ğŸ“ Organize Your Dataset](#-1-organize-your-dataset)
2. [ğŸ“ Document Your Dataset](#-2-document-your-dataset)
3. [ğŸ“Š Explore and Analyze](#-3-explore-and-analyze)
4. [ğŸ§¬ Declare Metadata](#-4-declare-metadata)
5. [â™»ï¸ Reuse and Share](#-5-reuse-and-share)
6. [ğŸ¤ Collaborate](#-6-collaborate)

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Pandas (for CSV handling)
- Git, Markdown, and basic knowledge of metadata standards

### Installation

```bash
# Clone the repository
git clone https://github.com/ryfor/RYFOR-data-template.git
cd RYFOR-data-template

# Create environment
conda env create -f environment.yml
conda activate ryfor-data-template
```

---

## ğŸ“ 1. Organize Your Dataset

Place your raw data files into:

```
data/raw/
```

If needed, you can add `data/processed/` for cleaned or transformed versions.

---

## ğŸ“ 2. Document Your Dataset

Update the following files inside the `docs/` folder:

- `codebook.md`: Define variables and controlled vocabularies.
- `data_dictionary.md`: Describe each column and data type.
- `methodology.md`: Explain how the data was collected or generated.
- `quality_report.md`: Highlight data issues, cleaning steps, and completeness.

---

## ğŸ“Š 3. Explore and Analyze

Use the notebooks in the `notebooks/` folder:

- `01-explore_raw_data.ipynb`: Automatically summarizes and visualizes your dataset.
- Add your own notebooks like `02-preprocessing.ipynb`, `03-analysis.ipynb`, etc.

You can run them using:

```bash
jupyter notebook
```

---

## ğŸ§¬ 4. Declare Metadata

Your dataset includes several machine-readable metadata files:

- `datapackage.json`: For validation with Frictionless Data tools
- `.zenodo.json`: For automatic metadata ingestion when publishing on Zenodo
- `schemaorg.jsonld`: Embedded JSON-LD for discoverability in Google Dataset Search
- `dcat.ttl`: DCAT-compliant RDF metadata for data catalogs
- `CITATION.cff`: Citation metadata (DOI, version, authors)

These help ensure your dataset is **FAIR**: Findable, Accessible, Interoperable, and Reusable.

---

## â™»ï¸ 5. Reuse and Share

- Publish on [Zenodo](https://zenodo.org/) or [MendeleyData](https://data.mendeley.com/)
- Register a DOI (automatically with `.zenodo.json`)
- Share with institutions or platforms that support DCAT or Frictionless metadata
- Reference your dataset using the `CITATION.cff` format

---

## ğŸ¤ 6. Collaborate

Encourage contributions with:

- `CONTRIBUTING.md`
- `CODE_OF_CONDUCT.md`
- Open issues or pull requests for improvement.

---

## ğŸ—‚ï¸ Project Structure

```
dataset-template/
â”‚
â”œâ”€â”€ .github/                      # Community health files (issues, templates, policies)
â”‚   â””â”€â”€ ISSUE_TEMPLATE.md         # Template for reporting issues or suggestions
â”‚
â”œâ”€â”€ data/                         # All dataset files are stored here
â”‚   â”œâ”€â”€ external/                 # External data sources (raw, unaltered)
â”‚   â”œâ”€â”€ processed/                # Cleaned and transformed data ready for analysis
â”‚   â””â”€â”€ raw/                      # Primary raw data (e.g., metadata.csv, data.csv)
â”‚
â”œâ”€â”€ docs/                         # Human-readable documentation
â”‚   â”œâ”€â”€ data_dictionary.md        # Description of each dataset variable
â”‚   â”œâ”€â”€ ethical_considerations.md # Ethical checklist and research compliance notes
â”‚   â”œâ”€â”€ methodology.md            # Data collection and processing methodology
â”‚   â”œâ”€â”€ quality_report.md         # Data quality insights and validation output
â”‚   â””â”€â”€ README.md                 # Description of the documentation module
â”‚
â”œâ”€â”€ fair/                         # FAIR compliance statements and evidence
â”‚   â””â”€â”€ README.md                 # Summary of FAIR alignment strategies
â”‚
â”œâ”€â”€ metadata/                     # Machine-readable metadata for catalogs
â”‚   â”œâ”€â”€ dcat.ttl                  # DCAT RDF file for semantic catalogs
â”‚   â””â”€â”€ schemaorg.jsonld          # Schema.org metadata for Google Dataset Search
â”‚
â”œâ”€â”€ notebooks/                    # Interactive notebooks for data analysis
â”‚   â”œâ”€â”€ 00-quality_report.ipynb   # Quality control and summary statistics
â”‚   â”œâ”€â”€ 01-explore_raw_data.ipynb # Initial data exploration
â”‚   â”œâ”€â”€ 02-preprocessing.ipynb    # Cleaning and preprocessing steps
â”‚   â””â”€â”€ 03-analysis.ipynb         # Main analysis workflows
â”‚
â”œâ”€â”€ .gitignore                    # Git exclusions
â”œâ”€â”€ .zenodo.json                  # Zenodo-compatible metadata file
â”œâ”€â”€ CHANGELOG.md                  # Version history and changes
â”œâ”€â”€ CITATION.cff                  # Citation metadata (DOI, author, version)
â”œâ”€â”€ CODE_OF_CONDUCT.md            # Contributor behavior expectations
â”œâ”€â”€ CONTRIBUTING.md               # Guidelines for contributions
â”œâ”€â”€ datapackage.json              # Frictionless Data metadata descriptor
â”œâ”€â”€ LICENSE                       # Licensing terms (e.g., MIT)
â”œâ”€â”€ README.md                     # Main description of the dataset and usage
â”œâ”€â”€ trinity.win.commit.cmd        # Helper script (customizable for internal use)
â””â”€â”€ USAGE.md                      # How to use and adapt this dataset template
```
